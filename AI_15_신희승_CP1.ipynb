{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XfI9CgDOhxAc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "tnKutqdUhy6X",
        "outputId": "439e1cf7-8a9f-4726-e0ad-78a830dc3324"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f39ad2b-4c57-4574-b304-ee9786f51780\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f39ad2b-4c57-4574-b304-ee9786f51780\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving binary_dataset.csv to binary_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기 기능(★)\n",
        "def get_data(file_path : str = 'binary_dataset.csv' ):\n",
        "    '''\n",
        "    파일의 경로를 받아 pd.DataFrame타입의 데이터를 반환한다.\n",
        "\n",
        "    parameter\n",
        "        - file_path : 파일 경로\n",
        "\n",
        "    return:\n",
        "        - pandas.DataFrame타입의 데이터\n",
        "    '''\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "#시그모이드 함수\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    pandas.DataFrame, pandas.Series, numpy.ndarray, int, float 타입을 받아\n",
        "    해당 값에 시그모이드 함수를 적용시킨 결과를 반환한다.\n",
        "\n",
        "    paramter\n",
        "        - x:pandas.DataFrame, pandas.Series, numpy.ndarray, int, float\n",
        "\n",
        "    return:\n",
        "        - pandas.DataFrame : 모든 수치형 values에 시그모이드 함수 적용시킨 결과를 반환\n",
        "        - pandas.Series    : 모든 수치형 values에 시그모이드 함수 적용시킨 결과를 반환\n",
        "        - numpy.ndarray    : 모든 수치형 원소들에 시그모이드 함수를 적용시킨 결과를 반환\n",
        "        - int              : 시그모이드 함수를 적용시킨 결과를 반환\n",
        "        - float            : 시그모이드 함수를 적용시킨 결과를 반환\n",
        "    '''\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "# 크로스 엔트로피 손실값\n",
        "def cross_entropy(pred : np.array, target: np.array):\n",
        "    '''\n",
        "    예측 확률값과 target값을 numpy.ndarray형태로 받아서 cross_entropy loss를 반환\n",
        "\n",
        "    paramter:\n",
        "        - pred   : 예측 확률값이 담긴 numpy.ndarray\n",
        "        - target : target값이 담긴 numpy.ndarray\n",
        "\n",
        "    return: \n",
        "        - cross_entropy_loss값\n",
        "    '''\n",
        "    delta = 1e-7\n",
        "    return -np.sum(target*np.log(pred+delta))\n",
        "\n",
        "# 독립 종속 변수 분리\n",
        "def split_X_y(df: pd.DataFrame , target: str):\n",
        "    '''\n",
        "    pandas.DataFrame과 target변수 명을 입력받아서 pandas.DataFrame 형태의 input\n",
        "    데이터와 pandas.Series형태의 target데이터를 반환한다.\n",
        "\n",
        "    paramter:\n",
        "        - df     : 분리할 pandas.DataFrame형태의 데이터\n",
        "        - target : target변수명 str\n",
        "\n",
        "    return:\n",
        "        - X : pandas.DataFrame 형태의 input 데이터\n",
        "        - y : pandas.Series형태의 target데이터\n",
        "    \n",
        "    '''\n",
        "    X = df.drop(target, axis=1)\n",
        "    y = df[target]\n",
        "    return X, y\n",
        "\n",
        "# 데이터셋 분리 기능(★)\n",
        "class split_train_test:\n",
        "    '''\n",
        "    트레이닝셋과 테스트셋을 분리하는 기능\n",
        "\n",
        "    Args:\n",
        "        - *array       : array 하나 이상의 numpy.ndarray, pandas.DataFrame, pandas.Series를 받음\n",
        "        - shuffle      : boolean 값을 받아 True면 데이터를 섞고 False면 섞지 않음 (default = False)\n",
        "        - test_szie    : 데스트셋의 크기를 비율로 표시 (default = 0.2)\n",
        "        - randaom_seed : 난수 고정을 위한 시드값 (default = None)\n",
        "\n",
        "    change_test_size:\n",
        "        테스트 사이즈의 비율을 변경한다.\n",
        "    \n",
        "        Args:\n",
        "            - test_szie    : 데스트셋의 크기를 비율로 표시\n",
        "            - randaom_seed : 난수 고정을 위한 시드값 (default = None)\n",
        "    \n",
        "    get_trainset:\n",
        "        입력 데이터셋에서 트레인셋을 분리하여 반환한다.\n",
        "\n",
        "        return: 트레인데이터셋\n",
        "\n",
        "    get_testset:\n",
        "        입력 데이터셋에서 테스트셋을 분리하여 반환한다.\n",
        "\n",
        "        return: 테스트 데이터셋\n",
        "    '''\n",
        "    def __init__(self, *array, shuffle : bool = False, test_size : float = 0.2, random_seed : int =None):\n",
        "        if random_seed !=None:\n",
        "            np.random.seed(random_seed)\n",
        "        self.array = array\n",
        "        if shuffle == True:\n",
        "            self.array= [df.sample(frac=1.0).reset_index(drop=True) for df in self.array]\n",
        "        self.split_idx = tuple(int(len(df)*(1-test_size)) for df in self.array)\n",
        "        self.train = None\n",
        "        self.test = None\n",
        "\n",
        "    def change_test_size(self, test_size : float , random_seed : int=None):\n",
        "        if random_seed != None:\n",
        "            np.random.seed(random_seed)\n",
        "        self.split_idx = tuple(int(len(df)*(1-test_size)) for df in self.array)\n",
        "        self.train = None\n",
        "        self.test = None\n",
        "    # 학습 데이터 분리 기능(★)\n",
        "    def get_trainset(self):\n",
        "        self.train = tuple(df[:idx] for df,idx in tuple(zip(self.array,self.split_idx)))\n",
        "        if len(self.train) ==1:\n",
        "            return self.train[0]\n",
        "        elif len(self.train) >1:\n",
        "            return self.train\n",
        "    # 테스트 데이터 분리 기능(★)\n",
        "    def get_testset(self):\n",
        "        self.test = tuple(df[idx:] for df,idx in tuple(zip(self.array,self.split_idx)))\n",
        "        if len(self.test) ==1:\n",
        "            return self.test[0]\n",
        "        elif len(self.test) >1:\n",
        "            return self.test\n",
        "\n",
        "# 스케일링 기능\n",
        "class Scaler:\n",
        "    '''\n",
        "    pd.DataFrame형태의 데이터를 입력받아 스케일링된 값들을 갖는 \n",
        "    데이터프레임을 반환한다.\n",
        "\n",
        "    Args: \n",
        "        - method : 스케일러의 유형 선택 ['MinMax', 'Standard']\n",
        "    \n",
        "    fit:\n",
        "        해당 데이터에 맞는 스케일러를 생성한다.\n",
        "    \n",
        "        Args: \n",
        "            - df : 스케일러 생성 기준이 되는 pandas.DataFrame, pandas.Series, numpy.ndarray형태의 데이터\n",
        "    \n",
        "    transform:\n",
        "        생성된 스케일러를 입력받은 데이터에 적용시킨다.\n",
        "    \n",
        "        Args:\n",
        "            - df : 스케일러를 적용할 pandas.DataFrame, pandas.Series, numpy.ndarray형태의 데이터\n",
        "    \n",
        "        return:\n",
        "            스케일링이 적용된 데이터 프레임\n",
        "        \n",
        "\n",
        "    fit_transform:\n",
        "        fit과 transform 메서드의 기능을 한번에 수행한다.\n",
        "    \n",
        "        Args:\n",
        "            - df : 스케일러를 생성하고 적용시킬 pandas.DataFrame, pandas.Series, numpy.ndarray형태의 데이터\n",
        "    \n",
        "        return:\n",
        "            스케일링이 적용된 데이터 프레임\n",
        "    \n",
        "    '''\n",
        "    def __init__(self, method : str = 'MinMax'):\n",
        "        self.scaler = None\n",
        "        self.divide = None\n",
        "        self.method = method\n",
        "        self.avg = None \n",
        "        self.mini = None\n",
        "        if method not in ['MinMax', 'Standard']:\n",
        "            raise ValueError(\"Select method list : 'MinMax', 'Standard'\")\n",
        "\n",
        "    def fit(self, df ):\n",
        "        if self.method == 'MinMax':\n",
        "            self.divide = (df.max() - df.min())\n",
        "            self.mini = df.min()\n",
        "        elif self.method == 'Standard':\n",
        "            self.divide = df.std()\n",
        "            self.avg = df.mean()\n",
        "\n",
        "    def transform(self,df):\n",
        "        if self.method == 'MinMax':\n",
        "            return (df - self.mini) / self.divide\n",
        "        elif self.method == 'Standard':\n",
        "            return (df - self.avg) / self.divide\n",
        "\n",
        "    def fit_transform(self, df):\n",
        "        self.fit(df)\n",
        "        return self.transform(df)\n",
        "\n",
        "class Dense:\n",
        "    '''\n",
        "    단층 신경망을 위해 만든 Dense class\n",
        "    Dense Layer 생성 및 순전파, 오차계산 시행\n",
        "\n",
        "    Args :\n",
        "        - unit            : 출력값의 수\n",
        "        - input_len     : 입력값의 변수 개수(default = None)\n",
        "        - activation_func : 적용할 활성함수(function)\n",
        "\n",
        "\n",
        "    initialization_parameter:\n",
        "        가중치와 편향을 초기화\n",
        "    \n",
        "        Args:\n",
        "            - method      : 가중치 초기화 방법 ['Xavier', 'He', 'Random']\n",
        "            - random_seed : 난수 고정 seed값\n",
        "\n",
        "    Input:\n",
        "        입력 데이터를 받아서 self.input_len을 수정하는 기능을함\n",
        "\n",
        "        Args : \n",
        "            - X : 입력 데이터를 입력 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        " \n",
        "\n",
        "    data_shuffle:\n",
        "        데이터를 뒤섞는 기능\n",
        "\n",
        "        Args:\n",
        "            - X : input 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - y : target 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "\n",
        "        return \n",
        "            - X : shuffle한 input 데이터 (numpy.ndarray)\n",
        "            - y : shuffle한 target 데이터 (numpy.ndarray)\n",
        "    \n",
        "    \n",
        "    get_loss\n",
        "        numpy.ndarray 타입의 예측 확률값과 target값을 받아서 손실함수를 계산\n",
        "\n",
        "        Args:\n",
        "            - pred_proba : numpy.ndarray 타입의 예측 확률\n",
        "            - target     : numpy.ndarray 타입의 target\n",
        "            - for_train  : train에 사용되는지 여부 (default = False)\n",
        "\n",
        "        return:\n",
        "            - for_train \n",
        "                - True  : 평균 loss를 반환\n",
        "                - Fasle : return하지 않고 손실함수 리스트에 추가\n",
        "\n",
        "\n",
        "    get_acc\n",
        "        np.ndarray 타입의 예측 확률값과 target값을 받아서 정확도를 계산\n",
        "\n",
        "        Args:\n",
        "            - pred_result : np.ndarray 타입의 예측값 \n",
        "            - target      : np.ndarray 타입의 target값\n",
        "            - for_train  : train에 사용되는지 여부 (default = False)\n",
        "\n",
        "    batch_gen\n",
        "        batch단위 연산을 위해 df, batch_size를 입력받아 제너레이터를 만들어준다.\n",
        "        (나누어 떨어지지 않는다면 나머지는 버려준다.)\n",
        "\n",
        "        Args:\n",
        "            - df         : 베치크기만큼 뽑아줄 데이터셋 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - batch_size : 배치의 크기\n",
        "\n",
        "        yield: 배치사이즈에 맞는 인풋 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "\n",
        "    forward\n",
        "        입력값을 받아 예측 값 혹은 예측확률을 반환한다.\n",
        "\n",
        "        Args:\n",
        "            - X           : 입력 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - batch_size  : 배치 사이즈 (default = None)\n",
        "            - threshold   : 임계치 (default = 0.5)\n",
        "            - proba       : return값으로 proba를 반환할지 여부 (default = False)\n",
        "            - random_seed : 난수 고정을 위한 랜덤 시드 값\n",
        "\n",
        "        return      \n",
        "            proba \n",
        "                - True  : 결과의 확률값으로 반환 (numpy.ndarray)\n",
        "                - False : 결과값으로 반환 (numpy.ndarray)\n",
        "        \n",
        "\n",
        "    fit(beta)\n",
        "        학습하며(아직 역전파 과정을 구현못해서 손실함수 계산까지의 과정만 진행) \n",
        "        가중치를 반환해주고 매 에포크마다 성능과 손실을 반환한다.\n",
        "\n",
        "    Args:\n",
        "        - X            : 입력 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "        - y            : Target 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "        - batch_size   : 배치 사이즈\n",
        "        - epochs       : 학습할 epoch수 (default = 1)\n",
        "        - threshold    : 임계치 (default = 0.5)\n",
        "        - random_seed  : 난수 고정을 위한 seed값\n",
        "    '''\n",
        "\n",
        "    def __init__(self, unit : int , activation_func , input_len : int = None):\n",
        "        self.unit = unit\n",
        "        self.activation_func = activation_func\n",
        "        self.input_len = input_len\n",
        "        self.W =None\n",
        "        self.b =None\n",
        "        self.batch_loss = np.array([])\n",
        "        self.batch_acc = np.array([])\n",
        "    \n",
        "    # 파라미터와 편향 생성 기능(★)\n",
        "    def initialization_parameter(self, method :str = 'Xavier', random_seed: int = None):\n",
        "        if random_seed != None:\n",
        "            np.random.seed(random_seed)\n",
        "        input_len = self.input_len\n",
        "    \n",
        "        if method == 'Xavier':\n",
        "            self.W = np.random.normal(0, 1/np.sqrt(input_len+self.unit), (input_len, self.unit))\n",
        "        elif method == 'He':\n",
        "            self.W = np.random.normal(0, 1/np.sqrt(input_len), (input_len, self.unit))\n",
        "        elif method == 'Random':\n",
        "            self.W = np.random.randn(input_len, self.unit)\n",
        "        else:\n",
        "            raise ValueError(\"Select method list : 'Xavier', 'He', 'Random'\")\n",
        "        \n",
        "        self.b = np.random.randn(1,self.unit) \n",
        "\n",
        "    def Input(self,X):\n",
        "        self.input_len = X.shape[-1]\n",
        "\n",
        "    # 데이터 뒤섞기(★)\n",
        "    def data_shuffle(self,X,y, random_seed = None):\n",
        "        if type(X) != np.array:\n",
        "            X = np.array(X)\n",
        "        if type(y) != np.array:\n",
        "            y = np.array(y)\n",
        "        if random_seed !=None:\n",
        "            np.random.seed(random_seed)\n",
        "        idx = np.arange(len(X))\n",
        "        np.random.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        y = y[idx]\n",
        "        return X,y\n",
        "\n",
        "    #loss 연산 기능(★)\n",
        "    def get_loss(self,pred_proba : np.array, target: np.array, for_train : bool =False):\n",
        "        if for_train == True:\n",
        "            self.batch_loss = np.append(self.batch_loss,np.mean(cross_entropy(pred_proba, target)))\n",
        "        else:\n",
        "            return np.mean(cross_entropy(np.array(pred_proba), target))\n",
        "\n",
        "    # 정확도 연산 기능(★)\n",
        "    def get_acc(self,pred_result: np.array, target : np.array, for_train=False):\n",
        "        if for_train == True:\n",
        "            self.batch_acc = np.append(self.batch_acc,np.mean(pred_result==target))\n",
        "        else:\n",
        "            return np.mean(pred_result==target)\n",
        "    \n",
        "    # batch generator\n",
        "    def batch_gen(self , X, batch_size):    \n",
        "        X_len = len(X)\n",
        "        for batch in range(X_len//batch_size):\n",
        "            yield X[batch*batch_size:batch*batch_size+batch_size]\n",
        "        \n",
        "    # 미니배치를 고려한 학습 데이터 기반의 신경망 연산 및 이진 판단 예측 기능(★)\n",
        "    def forward(self, X, batch_size = None, threshold = 0.5, proba=False,random_seed =None):\n",
        "        if self.input_len == None:\n",
        "            self.Input(X)\n",
        "        \n",
        "        if type(self.W) == type(None):\n",
        "            self.initialization_parameter(random_seed = random_seed)\n",
        "\n",
        "        if random_seed !=None:\n",
        "            np.random.seed(random_seed)\n",
        "        \n",
        "        if type(X) != np.array:\n",
        "            X = np.array(X).reshape(-1,self.input_len)\n",
        "        \n",
        "        \n",
        "        pred_proba_res = []\n",
        "        pred_result_res = []\n",
        "\n",
        "        if batch_size != None:\n",
        "            # for mini_batch,batch  in self.batch_gen(X, batch_size):\n",
        "            mini_batch = self.batch_gen(X, batch_size)\n",
        "            \n",
        "            while True:\n",
        "                try:\n",
        "                    pred_proba = self.activation_func(next(mini_batch)@self.W + self.b)\n",
        "                    pred_proba_res.append(pred_proba)\n",
        "                    pred_result = np.where(pred_proba >= threshold, 1, 0)\n",
        "                    pred_result_res.append(pred_result)\n",
        "                except:\n",
        "                    break\n",
        "        else: \n",
        "            pred_proba = self.activation_func(X@self.W + self.b)\n",
        "            pred_proba_res.append(pred_proba)\n",
        "            pred_result = np.where(pred_proba > threshold, 1, 0)\n",
        "            pred_result_res.append(pred_result)\n",
        "        \n",
        "        if proba == True:\n",
        "            return np.array(pred_proba_res)\n",
        "        else:\n",
        "            return np.array(pred_result_res)\n",
        "\n",
        "    def fit(self, X, y, batch_size : int, epochs :int = 1, threshold : float = 0.5, random_seed :int = None): \n",
        "        if self.input_len == None:\n",
        "            self.Input(X)\n",
        "\n",
        "        if random_seed !=None:\n",
        "            np.random.seed(random_seed)\n",
        "\n",
        "        if type(X) != np.array:\n",
        "            X = np.array(X)\n",
        "        if type(y) != np.array:\n",
        "            y = np.array(y)\n",
        "        \n",
        "        if type(self.W) == type(None):\n",
        "            self.initialization_parameter()\n",
        "\n",
        "        for epoch in range(1,epochs+1):\n",
        "            np.random.seed(random_seed)\n",
        "\n",
        "            X,y = self.data_shuffle(X,y)\n",
        "            \n",
        "            self.batch_loss = np.array([])\n",
        "            self.batch_acc = np.array([])\n",
        "\n",
        "            pred_proba = self.forward(X, batch_size = batch_size, threshold = threshold, proba= True)\n",
        "            pred_result = self.forward(X, batch_size = batch_size, threshold = threshold, proba= False)\n",
        "            target = y[:len(pred_proba.reshape(-1))]\n",
        "            target = target.reshape(pred_proba.shape)\n",
        "            \n",
        "            self.get_loss(pred_proba, target, for_train = True)\n",
        "        \n",
        "            self.get_acc(pred_result, target, for_train = True)\n",
        "\n",
        "            total_loss = round(np.mean(self.batch_loss),3)\n",
        "            total_acc = round(np.mean(self.batch_acc),3)\n",
        "\n",
        "            print(f'[EPOCH {epoch}] TrainData - Loss = {total_loss}, Accuracy = {total_acc}')\n",
        "            '''\n",
        "            역전파\n",
        "            '''\n",
        "\n",
        "\n",
        "class Sequential:\n",
        "    '''\n",
        "    하나 이상의 Layer를 쌓아서 순차적으로 순전파 과정을 진행하고 마지막 layer에서 결과를 반환한다.\n",
        "\n",
        "    add\n",
        "        layer를 sequence(self.layers)에 추가한다. 이때 layer의 이름을 설정가능하고 따로 지정하지 않는다면\n",
        "        해당 layer객체의 이름을 사용한다.\n",
        "        \n",
        "        Args:\n",
        "            - layer : sequence에 추가할 layer 객체\n",
        "            - Name  : 해당 layer의 명 (default = None [이 경우 해당 클래스의 이름으로 layer명을 설정한다.])\n",
        "\n",
        "    data_shuffle:\n",
        "        데이터를 뒤섞는 기능\n",
        "\n",
        "        Args:\n",
        "            - X : input 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - y : target 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "\n",
        "        return \n",
        "            - X : shuffle한 input 데이터 (numpy.ndarray)\n",
        "            - y : shuffle한 target 데이터 (numpy.ndarray)\n",
        "    \n",
        "    \n",
        "    get_loss\n",
        "        numpy.ndarray 타입의 예측 확률값과 target값을 받아서 손실함수를 계산\n",
        "\n",
        "        Args:\n",
        "            - pred_proba : numpy.ndarray 타입의 예측 확률\n",
        "            - target     : numpy.ndarray 타입의 target\n",
        "            - for_train  : train에 사용되는지 여부 (default = False)\n",
        "\n",
        "        return:\n",
        "            - for_train \n",
        "                - True  : 평균 loss를 반환\n",
        "                - Fasle : return하지 않고 손실함수 리스트에 추가\n",
        "\n",
        "\n",
        "    get_acc\n",
        "        np.ndarray 타입의 예측 확률값과 target값을 받아서 정확도를 계산\n",
        "\n",
        "        Args:\n",
        "            - pred_result : np.ndarray 타입의 예측값 \n",
        "            - target      : np.ndarray 타입의 target값\n",
        "            - for_train  : train에 사용되는지 여부 (default = False)\n",
        "\n",
        "    batch_gen\n",
        "        batch단위 연산을 위해 df, batch_size를 입력받아 제너레이터를 만들어준다.\n",
        "        (나누어 떨어지지 않는다면 나머지는 버려준다.)\n",
        "\n",
        "        Args:\n",
        "            - df         : 베치크기만큼 뽑아줄 데이터셋 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - batch_size : 배치의 크기\n",
        "\n",
        "        yield: 배치사이즈에 맞는 인풋 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "\n",
        "    forward\n",
        "        입력값을 받아 예측 값 혹은 예측확률을 반환한다.\n",
        "\n",
        "        Args:\n",
        "            - X           : 입력 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "            - batch_size  : 배치 사이즈 (default = None)\n",
        "            - threshold   : 임계치 (default = 0.5)\n",
        "            - proba       : return값으로 proba를 반환할지 여부 (default = False)\n",
        "            - random_seed : 난수 고정을 위한 랜덤 시드 값\n",
        "\n",
        "        return      \n",
        "            proba \n",
        "                - True  : 결과의 확률값으로 반환 (numpy.ndarray)\n",
        "                - False : 결과값으로 반환 (numpy.ndarray)\n",
        "        \n",
        "\n",
        "    fit(beta)\n",
        "        학습하며(아직 역전파 과정을 구현못해서 손실함수 계산까지의 과정만 진행) \n",
        "        가중치를 반환해주고 매 에포크마다 성능과 손실을 반환한다.\n",
        "\n",
        "    Args:\n",
        "        - X            : 입력 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "        - y            : Target 데이터 (pandas.DataFrame, padnas.Series, numpy.ndarray)\n",
        "        - batch_size   : 배치 사이즈\n",
        "        - epochs       : 학습할 epoch수 (default = 1)\n",
        "        - threshold    : 임계치 (default = 0.5)\n",
        "        - random_seed  : 난수 고정을 위한 seed값\n",
        "\n",
        "    summary\n",
        "        모델 구조를 출력해주는 메서드\n",
        "        \n",
        "        ex)\n",
        "        ================================================================================\n",
        "        Layer (type)                    Output Shape                    Params #\n",
        "        ================================================================================\n",
        "        Dense_1 (Dense)                  (None,4)                         36\n",
        "        --------------------------------------------------------------------------------\n",
        "        Dense_2 (Dense)                  (None,4)                         20\n",
        "        --------------------------------------------------------------------------------\n",
        "        Dense_3 (Dense)                  (None,1)                         5\n",
        "        --------------------------------------------------------------------------------\n",
        "        ================================================================================\n",
        "        Total Params :  61\n",
        "        ================================================================================\n",
        "\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.layers = {}\n",
        "        self.batch_loss = np.array([])\n",
        "        self.batch_acc = np.array([])\n",
        "    \n",
        "\n",
        "    def add(self, layer , Name : str=None):\n",
        "        if Name == None:\n",
        "            Name = type(layer).__name__+'_'\n",
        "            num=1\n",
        "            Name_select = Name+str(num)\n",
        "            while Name_select in self.layers.keys():\n",
        "                num+=1\n",
        "                Name_select = Name+str(num)\n",
        "            Name =  Name_select\n",
        "        \n",
        "        if  Name in self.layers.keys():\n",
        "            raise ValueError(f'{Name}은 이미 sequence에 존재합니다.')\n",
        "\n",
        "        self.layers[Name] = layer\n",
        "\n",
        "    def data_shuffle(self,X,y, random_seed = None):\n",
        "        if type(X) != np.array:\n",
        "            X = np.array(X)\n",
        "        if type(y) != np.array:\n",
        "            y = np.array(y)\n",
        "        if random_seed !=None:\n",
        "            np.random.seed(random_seed)\n",
        "        idx = np.arange(len(X))\n",
        "        np.random.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        y = y[idx]\n",
        "        return X,y\n",
        "\n",
        "     #loss 연산 기능(★)\n",
        "    def get_loss(self,pred_proba, target, for_train=False):\n",
        "        if for_train == True:\n",
        "            self.batch_loss = np.append(self.batch_loss,np.mean(cross_entropy(pred_proba, target)))\n",
        "        else:\n",
        "            return np.mean(cross_entropy(np.array(pred_proba), target))\n",
        "\n",
        "    # 정확도 연산 기능(★)\n",
        "    def get_acc(self,pred_result, target, for_train=False):\n",
        "        if for_train == True:\n",
        "            self.batch_acc = np.append(self.batch_acc,np.mean(pred_result==target))\n",
        "        else:\n",
        "            return np.mean(pred_result==target)\n",
        "\n",
        "    def forward(self, X, batch_size :int = None, threshold :float = 0.5, proba :bool =False, random_seed :int =None):\n",
        "        input = X\n",
        "        if len(self.layers) > 1:\n",
        "            for layer in list(self.layers.values())[:-1]:\n",
        "                input = layer.forward(input, batch_size = batch_size, threshold = threshold, proba = True, random_seed=random_seed)\n",
        "            result = list(self.layers.values())[-1].forward(input, batch_size = batch_size, threshold = threshold, proba = proba, random_seed=random_seed)\n",
        "        else:\n",
        "            result = list(self.layers.values())[-1].forward(input, batch_size = batch_size, threshold = threshold, proba = proba, random_seed=random_seed)\n",
        "\n",
        "        return result\n",
        "\n",
        "    \n",
        "    def fit(self, X, y, batch_size : int =None, epochs :int = 1, threshold :float = 0.5, random_seed : int= None):\n",
        "        \n",
        "        for epoch in range(1,epochs+1):\n",
        "            np.random.seed(random_seed)\n",
        "\n",
        "            X,y = self.data_shuffle(X,y)\n",
        "            \n",
        "            self.batch_loss = np.array([])\n",
        "            self.batch_acc = np.array([])\n",
        "\n",
        "            pred_proba = self.forward(X, batch_size = batch_size, threshold = threshold, proba= True)\n",
        "            pred_result = self.forward(X, batch_size = batch_size, threshold = threshold, proba= False)\n",
        "            target = y[:len(pred_proba.reshape(-1))]\n",
        "            target = target.reshape(pred_proba.shape)\n",
        "            \n",
        "            self.get_loss(pred_proba, target, for_train = True)\n",
        "        \n",
        "            self.get_acc(pred_result, target, for_train = True)\n",
        "\n",
        "            total_loss = round(np.mean(self.batch_loss),3)\n",
        "            total_acc = round(np.mean(self.batch_acc),3)\n",
        "\n",
        "            print(f'[EPOCH {epoch}] TrainData - Loss = {total_loss}, Accuracy = {total_acc}')\n",
        "    \n",
        "    def summary(self):\n",
        "        print('='*80)\n",
        "        print('Layer (type)'+' '*20+'Output Shape'+ ' '*20+'Params #')\n",
        "        print('='*80)\n",
        "        last_name = list(self.layers.keys())[-1]\n",
        "        total_Params = 0\n",
        "        for name, layer in self.layers.items():\n",
        "            layer_type = ' ('+type(layer).__name__+')'\n",
        "            name += layer_type\n",
        "            name_len = len(name)\n",
        "            output_shape = f'(None,{layer.unit})'\n",
        "            output_shape_len = len(output_shape)\n",
        "            Params = layer.unit*(layer.input_len+1)\n",
        "            total_Params += Params\n",
        "            print(name+' '*(33 - name_len)+ output_shape + ' '*(33-output_shape_len)+ str(Params))\n",
        "            print('-'*80)\n",
        "        print('='*80)\n",
        "        print('Total Params : ', total_Params)\n",
        "        print('='*80)\n",
        "\n"
      ],
      "metadata": {
        "id": "Yn5IbAOGHtnk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \n",
        "    df = get_data()\n",
        "    \n",
        "    spliter = split_train_test(df)\n",
        "    \n",
        "    train = spliter.get_trainset()\n",
        "    \n",
        "    test = spliter.get_testset()\n",
        "\n",
        "    X_train, y_train = split_X_y(train, 'y')\n",
        "    X_test, y_test = split_X_y(test, 'y')\n",
        "    \n",
        "    scaler = Scaler()\n",
        "\n",
        "    scaler.fit_transform(X_train)\n",
        "    scaler.transform(X_test)\n",
        "\n",
        "    Net = Sequential()\n",
        "\n",
        "    Net.add(Dense(1,sigmoid))\n",
        "\n",
        "    Net.fit(X_train, y_train, batch_size=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "dW3KTghvCuk1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ_AtjelQ69S",
        "outputId": "48581014-8d1b-4733-9a48-18aaf947c109"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH 1] TrainData - Loss = 48.288, Accuracy = 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필수 구현 함수(메서드) 테스트"
      ],
      "metadata": {
        "id": "h4ZAU57xx94j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 데이터로드 함수\n",
        "file_path = \"binary_dataset.csv\" #@param {type:\"string\"}\n",
        "df = get_data(file_path)\n",
        "df"
      ],
      "metadata": {
        "id": "jZEvgFPRqSrd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "7ae9cbff-bb0f-48f7-e75b-d1c9dac70b20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            x1         x2        x3         x4          x5         x6  \\\n",
              "0   136.093750  51.691005 -0.045909  -0.271816    9.342809  38.096400   \n",
              "1    99.367188  41.572202  1.547197   4.154106   27.555184  61.719016   \n",
              "2   100.890625  51.890394  0.627487  -0.026498    3.883779  23.045267   \n",
              "3   120.554688  45.549905  0.282924   0.419909    1.358696  13.079034   \n",
              "4   121.882812  53.042675  0.200521  -0.282219    2.116221  16.580876   \n",
              "5   125.210938  51.175197  0.139851  -0.385737    1.147993  12.414012   \n",
              "6   141.968750  50.470898  0.244974  -0.342665    2.823579  16.238188   \n",
              "7   136.500000  49.932767  0.044623  -0.374311    1.555184  12.813538   \n",
              "8    83.679688  36.379281  0.572532   2.664611    4.040970  23.169129   \n",
              "9    27.765625  28.666042  5.770087  37.419009   73.112876  62.070220   \n",
              "10  135.859375  51.937272  0.065769  -0.366114   20.774247  52.772648   \n",
              "11  114.281250  41.253965  0.411821   0.616996    2.412207  20.427942   \n",
              "12  112.437500  38.295673  0.501943   1.074840    2.812709  18.136883   \n",
              "13   23.625000  29.948654  5.688038  35.987172  146.568562  82.394624   \n",
              "14   94.585938  35.779823  1.187309   3.687469    6.071070  29.760400   \n",
              "15  137.242188  46.454740  0.045257  -0.438858   59.495819  77.755357   \n",
              "16  123.531250  53.348784  0.072078  -0.071601    0.781773  10.570833   \n",
              "17  123.468750  45.475085  0.345781   0.647415   32.919732  65.094197   \n",
              "18  103.523438  45.725739  0.336533   0.520558   11.289298  39.116453   \n",
              "19  107.929688  50.581954  0.320399   0.277613    2.022575  19.806556   \n",
              "\n",
              "           x7          x8  y  \n",
              "0    4.345438   18.673649  0  \n",
              "1    2.208808    3.662680  1  \n",
              "2    6.953168   52.279440  0  \n",
              "3   13.312141  212.597029  1  \n",
              "4    8.947603   91.011762  0  \n",
              "5   14.068797  228.131554  0  \n",
              "6    8.207744   85.532584  0  \n",
              "7   13.314339  214.813089  0  \n",
              "8    7.006681   53.514005  0  \n",
              "9    1.268206    1.082920  1  \n",
              "10   2.730909    6.607440  0  \n",
              "11   9.198392   88.370580  0  \n",
              "12   7.859968   71.299449  0  \n",
              "13  -0.274902   -1.121848  1  \n",
              "14   5.318767   28.698048  1  \n",
              "15   0.719748   -1.183162  0  \n",
              "16  17.118300  339.660826  0  \n",
              "17   1.605538    0.871364  1  \n",
              "18   3.509139   11.503980  0  \n",
              "19  10.472251  113.011537  0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-385e6da0-7fc3-4820-ab70-003ac19f2d87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136.093750</td>\n",
              "      <td>51.691005</td>\n",
              "      <td>-0.045909</td>\n",
              "      <td>-0.271816</td>\n",
              "      <td>9.342809</td>\n",
              "      <td>38.096400</td>\n",
              "      <td>4.345438</td>\n",
              "      <td>18.673649</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.367188</td>\n",
              "      <td>41.572202</td>\n",
              "      <td>1.547197</td>\n",
              "      <td>4.154106</td>\n",
              "      <td>27.555184</td>\n",
              "      <td>61.719016</td>\n",
              "      <td>2.208808</td>\n",
              "      <td>3.662680</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.890625</td>\n",
              "      <td>51.890394</td>\n",
              "      <td>0.627487</td>\n",
              "      <td>-0.026498</td>\n",
              "      <td>3.883779</td>\n",
              "      <td>23.045267</td>\n",
              "      <td>6.953168</td>\n",
              "      <td>52.279440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120.554688</td>\n",
              "      <td>45.549905</td>\n",
              "      <td>0.282924</td>\n",
              "      <td>0.419909</td>\n",
              "      <td>1.358696</td>\n",
              "      <td>13.079034</td>\n",
              "      <td>13.312141</td>\n",
              "      <td>212.597029</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121.882812</td>\n",
              "      <td>53.042675</td>\n",
              "      <td>0.200521</td>\n",
              "      <td>-0.282219</td>\n",
              "      <td>2.116221</td>\n",
              "      <td>16.580876</td>\n",
              "      <td>8.947603</td>\n",
              "      <td>91.011762</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>125.210938</td>\n",
              "      <td>51.175197</td>\n",
              "      <td>0.139851</td>\n",
              "      <td>-0.385737</td>\n",
              "      <td>1.147993</td>\n",
              "      <td>12.414012</td>\n",
              "      <td>14.068797</td>\n",
              "      <td>228.131554</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>141.968750</td>\n",
              "      <td>50.470898</td>\n",
              "      <td>0.244974</td>\n",
              "      <td>-0.342665</td>\n",
              "      <td>2.823579</td>\n",
              "      <td>16.238188</td>\n",
              "      <td>8.207744</td>\n",
              "      <td>85.532584</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>136.500000</td>\n",
              "      <td>49.932767</td>\n",
              "      <td>0.044623</td>\n",
              "      <td>-0.374311</td>\n",
              "      <td>1.555184</td>\n",
              "      <td>12.813538</td>\n",
              "      <td>13.314339</td>\n",
              "      <td>214.813089</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83.679688</td>\n",
              "      <td>36.379281</td>\n",
              "      <td>0.572532</td>\n",
              "      <td>2.664611</td>\n",
              "      <td>4.040970</td>\n",
              "      <td>23.169129</td>\n",
              "      <td>7.006681</td>\n",
              "      <td>53.514005</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>27.765625</td>\n",
              "      <td>28.666042</td>\n",
              "      <td>5.770087</td>\n",
              "      <td>37.419009</td>\n",
              "      <td>73.112876</td>\n",
              "      <td>62.070220</td>\n",
              "      <td>1.268206</td>\n",
              "      <td>1.082920</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>135.859375</td>\n",
              "      <td>51.937272</td>\n",
              "      <td>0.065769</td>\n",
              "      <td>-0.366114</td>\n",
              "      <td>20.774247</td>\n",
              "      <td>52.772648</td>\n",
              "      <td>2.730909</td>\n",
              "      <td>6.607440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>114.281250</td>\n",
              "      <td>41.253965</td>\n",
              "      <td>0.411821</td>\n",
              "      <td>0.616996</td>\n",
              "      <td>2.412207</td>\n",
              "      <td>20.427942</td>\n",
              "      <td>9.198392</td>\n",
              "      <td>88.370580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>112.437500</td>\n",
              "      <td>38.295673</td>\n",
              "      <td>0.501943</td>\n",
              "      <td>1.074840</td>\n",
              "      <td>2.812709</td>\n",
              "      <td>18.136883</td>\n",
              "      <td>7.859968</td>\n",
              "      <td>71.299449</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>23.625000</td>\n",
              "      <td>29.948654</td>\n",
              "      <td>5.688038</td>\n",
              "      <td>35.987172</td>\n",
              "      <td>146.568562</td>\n",
              "      <td>82.394624</td>\n",
              "      <td>-0.274902</td>\n",
              "      <td>-1.121848</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>94.585938</td>\n",
              "      <td>35.779823</td>\n",
              "      <td>1.187309</td>\n",
              "      <td>3.687469</td>\n",
              "      <td>6.071070</td>\n",
              "      <td>29.760400</td>\n",
              "      <td>5.318767</td>\n",
              "      <td>28.698048</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>137.242188</td>\n",
              "      <td>46.454740</td>\n",
              "      <td>0.045257</td>\n",
              "      <td>-0.438858</td>\n",
              "      <td>59.495819</td>\n",
              "      <td>77.755357</td>\n",
              "      <td>0.719748</td>\n",
              "      <td>-1.183162</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>123.531250</td>\n",
              "      <td>53.348784</td>\n",
              "      <td>0.072078</td>\n",
              "      <td>-0.071601</td>\n",
              "      <td>0.781773</td>\n",
              "      <td>10.570833</td>\n",
              "      <td>17.118300</td>\n",
              "      <td>339.660826</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>123.468750</td>\n",
              "      <td>45.475085</td>\n",
              "      <td>0.345781</td>\n",
              "      <td>0.647415</td>\n",
              "      <td>32.919732</td>\n",
              "      <td>65.094197</td>\n",
              "      <td>1.605538</td>\n",
              "      <td>0.871364</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>103.523438</td>\n",
              "      <td>45.725739</td>\n",
              "      <td>0.336533</td>\n",
              "      <td>0.520558</td>\n",
              "      <td>11.289298</td>\n",
              "      <td>39.116453</td>\n",
              "      <td>3.509139</td>\n",
              "      <td>11.503980</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>107.929688</td>\n",
              "      <td>50.581954</td>\n",
              "      <td>0.320399</td>\n",
              "      <td>0.277613</td>\n",
              "      <td>2.022575</td>\n",
              "      <td>19.806556</td>\n",
              "      <td>10.472251</td>\n",
              "      <td>113.011537</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-385e6da0-7fc3-4820-ab70-003ac19f2d87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-385e6da0-7fc3-4820-ab70-003ac19f2d87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-385e6da0-7fc3-4820-ab70-003ac19f2d87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 트레인 테스트셋 분리\n",
        "\n",
        "file_path = \"binary_dataset.csv\" \n",
        "df = get_data(file_path)\n",
        "\n",
        "print('원본 데이터\\n')\n",
        "print(df)\n",
        "print('-'*80)\n",
        "\n",
        "\n",
        "shuffle = False #@param {type:\"boolean\"}\n",
        "test_size = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "random_seed = 0 #@param {type:\"integer\"}\n",
        "dataset_type = \"Test\" #@param [\"Train\", 'Test']\n",
        "\n",
        "\n",
        "spliter = split_train_test(df, shuffle = shuffle, test_size= test_size, random_seed = random_seed)\n",
        "train = spliter.get_trainset()    \n",
        "test = spliter.get_testset()\n",
        "\n",
        "train_test_dict = {'Train': train,\n",
        "                   'Test': test}\n",
        "\n",
        "print(f'''shuffle:{shuffle}\n",
        "      test_size:{test_size}\n",
        "      random_seed:{random_seed}      \n",
        "      ''')\n",
        "\n",
        "print(f'''dataset_type : {dataset_type }\n",
        "      \n",
        "      {train_test_dict[dataset_type]}\n",
        "      ''')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8jXF_NF-oRr",
        "outputId": "abc6f9a7-7f99-4ebd-b1ba-4c86790ee095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 데이터\n",
            "\n",
            "            x1         x2        x3         x4          x5         x6  \\\n",
            "0   136.093750  51.691005 -0.045909  -0.271816    9.342809  38.096400   \n",
            "1    99.367188  41.572202  1.547197   4.154106   27.555184  61.719016   \n",
            "2   100.890625  51.890394  0.627487  -0.026498    3.883779  23.045267   \n",
            "3   120.554688  45.549905  0.282924   0.419909    1.358696  13.079034   \n",
            "4   121.882812  53.042675  0.200521  -0.282219    2.116221  16.580876   \n",
            "5   125.210938  51.175197  0.139851  -0.385737    1.147993  12.414012   \n",
            "6   141.968750  50.470898  0.244974  -0.342665    2.823579  16.238188   \n",
            "7   136.500000  49.932767  0.044623  -0.374311    1.555184  12.813538   \n",
            "8    83.679688  36.379281  0.572532   2.664611    4.040970  23.169129   \n",
            "9    27.765625  28.666042  5.770087  37.419009   73.112876  62.070220   \n",
            "10  135.859375  51.937272  0.065769  -0.366114   20.774247  52.772648   \n",
            "11  114.281250  41.253965  0.411821   0.616996    2.412207  20.427942   \n",
            "12  112.437500  38.295673  0.501943   1.074840    2.812709  18.136883   \n",
            "13   23.625000  29.948654  5.688038  35.987172  146.568562  82.394624   \n",
            "14   94.585938  35.779823  1.187309   3.687469    6.071070  29.760400   \n",
            "15  137.242188  46.454740  0.045257  -0.438858   59.495819  77.755357   \n",
            "16  123.531250  53.348784  0.072078  -0.071601    0.781773  10.570833   \n",
            "17  123.468750  45.475085  0.345781   0.647415   32.919732  65.094197   \n",
            "18  103.523438  45.725739  0.336533   0.520558   11.289298  39.116453   \n",
            "19  107.929688  50.581954  0.320399   0.277613    2.022575  19.806556   \n",
            "\n",
            "           x7          x8  y  \n",
            "0    4.345438   18.673649  0  \n",
            "1    2.208808    3.662680  1  \n",
            "2    6.953168   52.279440  0  \n",
            "3   13.312141  212.597029  1  \n",
            "4    8.947603   91.011762  0  \n",
            "5   14.068797  228.131554  0  \n",
            "6    8.207744   85.532584  0  \n",
            "7   13.314339  214.813089  0  \n",
            "8    7.006681   53.514005  0  \n",
            "9    1.268206    1.082920  1  \n",
            "10   2.730909    6.607440  0  \n",
            "11   9.198392   88.370580  0  \n",
            "12   7.859968   71.299449  0  \n",
            "13  -0.274902   -1.121848  1  \n",
            "14   5.318767   28.698048  1  \n",
            "15   0.719748   -1.183162  0  \n",
            "16  17.118300  339.660826  0  \n",
            "17   1.605538    0.871364  1  \n",
            "18   3.509139   11.503980  0  \n",
            "19  10.472251  113.011537  0  \n",
            "--------------------------------------------------------------------------------\n",
            "shuffle:False\n",
            "      test_size:0.7\n",
            "      random_seed:0      \n",
            "      \n",
            "dataset_type : Test\n",
            "      \n",
            "                  x1         x2        x3         x4          x5         x6  \\\n",
            "6   141.968750  50.470898  0.244974  -0.342665    2.823579  16.238188   \n",
            "7   136.500000  49.932767  0.044623  -0.374311    1.555184  12.813538   \n",
            "8    83.679688  36.379281  0.572532   2.664611    4.040970  23.169129   \n",
            "9    27.765625  28.666042  5.770087  37.419009   73.112876  62.070220   \n",
            "10  135.859375  51.937272  0.065769  -0.366114   20.774247  52.772648   \n",
            "11  114.281250  41.253965  0.411821   0.616996    2.412207  20.427942   \n",
            "12  112.437500  38.295673  0.501943   1.074840    2.812709  18.136883   \n",
            "13   23.625000  29.948654  5.688038  35.987172  146.568562  82.394624   \n",
            "14   94.585938  35.779823  1.187309   3.687469    6.071070  29.760400   \n",
            "15  137.242188  46.454740  0.045257  -0.438858   59.495819  77.755357   \n",
            "16  123.531250  53.348784  0.072078  -0.071601    0.781773  10.570833   \n",
            "17  123.468750  45.475085  0.345781   0.647415   32.919732  65.094197   \n",
            "18  103.523438  45.725739  0.336533   0.520558   11.289298  39.116453   \n",
            "19  107.929688  50.581954  0.320399   0.277613    2.022575  19.806556   \n",
            "\n",
            "           x7          x8  y  \n",
            "6    8.207744   85.532584  0  \n",
            "7   13.314339  214.813089  0  \n",
            "8    7.006681   53.514005  0  \n",
            "9    1.268206    1.082920  1  \n",
            "10   2.730909    6.607440  0  \n",
            "11   9.198392   88.370580  0  \n",
            "12   7.859968   71.299449  0  \n",
            "13  -0.274902   -1.121848  1  \n",
            "14   5.318767   28.698048  1  \n",
            "15   0.719748   -1.183162  0  \n",
            "16  17.118300  339.660826  0  \n",
            "17   1.605538    0.871364  1  \n",
            "18   3.509139   11.503980  0  \n",
            "19  10.472251  113.011537  0  \n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 파라미터와 평향 생성기능\n",
        "unit = 1 #@param {type:\"integer\"}\n",
        "input_len = 8 #@param {type:\"integer\"}\n",
        "activation_func = sigmoid\n",
        "\n",
        "Net = Dense(unit = unit, activation_func = activation_func, input_len = input_len)\n",
        "\n",
        "method = 'Xavier' #@param ['Xavier', 'He', 'Random']\n",
        "random_seed = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "Net.initialization_parameter(method = method, random_seed = random_seed)\n",
        "\n",
        "print(f'''W\n",
        "{Net.W}\n",
        "''')\n",
        "print('-'*80)\n",
        "print(f'''b\n",
        "{Net.b}\n",
        "''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eMQ_TClG1_L",
        "outputId": "7cc34f49-f5ef-4a13-f5aa-27c5be7a548d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W\n",
            "[[ 0.58801745]\n",
            " [ 0.13338574]\n",
            " [ 0.32624599]\n",
            " [ 0.7469644 ]\n",
            " [ 0.62251933]\n",
            " [-0.32575929]\n",
            " [ 0.31669614]\n",
            " [-0.0504524 ]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "b\n",
            "[[-0.10321885]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 데이터 뒤섞기\n",
        "\n",
        "df = get_data()\n",
        "    \n",
        "X, y = split_X_y(df, 'y')\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "Net = Dense(1, sigmoid)\n",
        "\n",
        "ranodm_seed = 0 #@param {type:\"integer\"}\n",
        "\n",
        "shuffle_X, shuffle_y= Net.data_shuffle(X, y, random_seed = random_seed)\n",
        "\n",
        "raw_dict = {'X': X, 'y': y}\n",
        "\n",
        "shuffle_dict = {'X': shuffle_X, 'y': shuffle_y}\n",
        "\n",
        "select = \"y\" #@param [\"X\", \"y\"] \n",
        "\n",
        "print(f'''\n",
        "raw_{select}\n",
        "{raw_dict[select]}\n",
        "\n",
        "''')\n",
        "print('-'*80)\n",
        "\n",
        "print(f'''\n",
        "shuffled_{select}\n",
        "{shuffle_dict[select]}\n",
        "''')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEE9I5UIM8lw",
        "outputId": "22bf0f72-0aee-4a1f-dc73-6f89b61409a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "raw_y\n",
            "[0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0]\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "shuffled_y\n",
            "[0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 손심 함수 계산\n",
        "df = get_data()\n",
        "    \n",
        "X, y = split_X_y(df, 'y')\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "Net = Dense(1, sigmoid)\n",
        "\n",
        "pred_proba = Net.forward(X, proba=True)\n",
        "\n",
        "print('cross_entropy: ',Net.get_loss(pred_proba, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0avgCmVjQAJf",
        "outputId": "0aa2f147-7ab8-4679-a610-a833aade154b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross_entropy:  -1.1952977317321753e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 정확도 계산\n",
        "df = get_data()\n",
        "    \n",
        "X, y = split_X_y(df, 'y')\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "Net = Dense(1, sigmoid)\n",
        "\n",
        "pred_result = Net.forward(X)\n",
        "\n",
        "print('accuracy : ', Net.get_acc(pred_result, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MhHmMKwT9O1",
        "outputId": "0f842f72-af11-45c0-e531-22893e2b3bdd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy :  0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 배치 단위 결과 반환\n",
        "\n",
        "df = get_data()\n",
        "    \n",
        "X, y = split_X_y(df, 'y')\n",
        "\n",
        "X = np.array(X)\n",
        "\n",
        "Net = Dense(1,sigmoid)\n",
        "\n",
        "batch_size = 6 #@param {type:\"integer\"}\n",
        "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "proba = False #@param {type:\"boolean\"}\n",
        "random_seed = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Net.forward(X, batch_size = batch_size, threshold = threshold, proba=proba,random_seed =None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbiVOh_7U0_u",
        "outputId": "84c0d3d4-72d1-4c0b-9c77-6e41fdfc40de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 구현 클래스(Sequential) 테스트"
      ],
      "metadata": {
        "id": "Q6SkuoOzaKhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 다층 신경망 순전파 + 오차,score 계산\n",
        "\n",
        "df = get_data()\n",
        "\n",
        "spliter = split_train_test(df)\n",
        "\n",
        "train = spliter.get_trainset()\n",
        "\n",
        "test = spliter.get_testset()\n",
        "\n",
        "X_train, y_train = split_X_y(train, 'y')\n",
        "X_test, y_test = split_X_y(test, 'y')\n",
        "\n",
        "scaler = Scaler()\n",
        "\n",
        "scaler.fit_transform(X_train)\n",
        "scaler.transform(X_test)\n",
        "\n",
        "Net = Sequential()\n",
        "\n",
        "hidden_layer_num = 2 #@param {type:\"integer\"}\n",
        "\n",
        "# 히든 노드의 아웃풋 크기를 순차적으로 리스트 형태로 입력\n",
        "hidden_node = [4,4] #@param {type:\"raw\"}\n",
        "\n",
        "for i in range(hidden_layer_num):\n",
        "    Net.add(Dense(hidden_node[i],sigmoid))\n",
        "\n",
        "Net.add(Dense(1,sigmoid))\n",
        "\n",
        "Net.fit(X_train, y_train, batch_size=4)\n",
        "\n",
        "print('\\n')\n",
        "print('Model summary')\n",
        "Net.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNZKh30BaQVj",
        "outputId": "3166eb44-6c93-4c02-bd0b-47f6f75ee61c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH 1] TrainData - Loss = 6.328, Accuracy = 0.688\n",
            "\n",
            "\n",
            "Model summary\n",
            "================================================================================\n",
            "Layer (type)                    Output Shape                    Params #\n",
            "================================================================================\n",
            "Dense_1 (Dense)                  (None,4)                         36\n",
            "--------------------------------------------------------------------------------\n",
            "Dense_2 (Dense)                  (None,4)                         20\n",
            "--------------------------------------------------------------------------------\n",
            "Dense_3 (Dense)                  (None,1)                         5\n",
            "--------------------------------------------------------------------------------\n",
            "================================================================================\n",
            "Total Params :  61\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}